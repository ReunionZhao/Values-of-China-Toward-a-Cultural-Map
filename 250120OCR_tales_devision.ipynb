{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提取故事内容 + 初步得到采录者信息和地点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理故事: 100%|██████████| 667/667 [00:00<00:00, 2292.73个/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成！结果已保存到 /Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/青海 目录中。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm  # 导入 tqdm 库\n",
    "\n",
    "# 定义文件路径\n",
    "input_file_path = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/中国民间故事集成 山东_青海_内蒙古_黑龙江/中国民间故事集成青海卷.txt\"\n",
    "output_dir = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/青海\"\n",
    "csv_file_path = os.path.join(output_dir, \"stories_info.csv\")\n",
    "\n",
    "number = 667\n",
    "# 创建输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 读取文件内容\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# 正则表达式匹配标题行（编号 + 可能存在的空格 + 分隔符 + 标题）\n",
    "title_pattern = re.compile(r\"(\\d{3})\\s*[•.。](.*?)\\n\")\n",
    "# 正则表达式匹配地点信息\n",
    "location_pattern = re.compile(r\"（(.*?)）\")\n",
    "# 正则表达式匹配讲述者信息\n",
    "narrator_pattern = re.compile(r\"讲\\s*述\\s*者[^\\w\\s]*(.*?)(?=\\d{4}|$)\", re.DOTALL)\n",
    "# 正则表达式匹配采录者信息\n",
    "recorder_pattern = re.compile(r\"采\\s*录\\s*者[^\\w\\s]*(.*?)(?=\\d{4}|$)\", re.DOTALL)\n",
    "# 正则表达式匹配讲述并记录信息\n",
    "narrator_recorder_pattern = re.compile(r\"讲\\s*述\\s*并\\s*记\\s*录[^\\w\\s]*(.*?)(?=\\d{4}|$)\", re.DOTALL)\n",
    "\n",
    "# 找到所有标题行的位置\n",
    "title_matches = list(title_pattern.finditer(content))\n",
    "\n",
    "# 初始化存储结果的列表\n",
    "stories_data = []\n",
    "\n",
    "# 遍历 001 到 725，逐个定位标题行\n",
    "for story_number in tqdm(range(1, number + 1), desc=\"处理故事\", unit=\"个\"):\n",
    "    # 格式化编号为 3 位数（如 001, 002, ..., 725）\n",
    "    story_number_str = f\"{story_number:03d}\"\n",
    "    \n",
    "    # 构造正则表达式，匹配当前编号的标题行\n",
    "    current_title_pattern = re.compile(rf\"{story_number_str}\\s*[•.。](.*?)\\n\")\n",
    "    title_match = current_title_pattern.search(content)\n",
    "    \n",
    "    if not title_match:\n",
    "        # 如果没有找到当前编号的标题行，跳过\n",
    "        continue\n",
    "\n",
    "    # 提取标题\n",
    "    story_title = title_match.group(1).strip()\n",
    "    story_name = f\"{story_number_str}{story_title}\"\n",
    "\n",
    "    # 提取地点信息\n",
    "    location_match = location_pattern.search(content[title_match.end():])\n",
    "    location = location_match.group(1).strip() if location_match else \"NaN\"\n",
    "\n",
    "    # 提取故事内容\n",
    "    if story_number < number:\n",
    "        # 查找下一个标题行\n",
    "        next_title_pattern = re.compile(rf\"{story_number + 1:03d}\\s*[•.。](.*?)\\n\")\n",
    "        next_title_match = next_title_pattern.search(content[title_match.end():])\n",
    "        if next_title_match:\n",
    "            # 当前故事的内容是从当前标题开始到下一个标题之前\n",
    "            story_content = content[title_match.start():title_match.end() + next_title_match.start()].strip()\n",
    "        else:\n",
    "            # 如果没有找到下一个标题行，则跳过\n",
    "            continue\n",
    "    else:\n",
    "        # 最后一个故事的内容是从当前标题开始到文件末尾\n",
    "        story_content = content[title_match.start():].strip()\n",
    "\n",
    "    # 提取信息（优先级：讲述者 > 采录者 > 讲述并记录）\n",
    "    narrator_match = narrator_pattern.search(story_content)\n",
    "    recorder_match = recorder_pattern.search(story_content)\n",
    "    narrator_recorder_match = narrator_recorder_pattern.search(story_content)\n",
    "\n",
    "    if narrator_match:\n",
    "        info_text = narrator_match.group(1).strip()  # 提取“讲述者”之后的内容\n",
    "        info_type = \"讲述者\"\n",
    "        # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "        info_text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", info_text)\n",
    "        # 剔除讲述者信息\n",
    "        story_content = story_content[:narrator_match.start()].strip()\n",
    "    elif recorder_match:\n",
    "        info_text = recorder_match.group(1).strip()  # 提取“采录者”之后的内容\n",
    "        info_type = \"采录者\"\n",
    "        # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "        info_text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", info_text)\n",
    "        # 剔除采录者信息\n",
    "        story_content = story_content[:recorder_match.start()].strip()\n",
    "    elif narrator_recorder_match:\n",
    "        info_text = narrator_recorder_match.group(1).strip()  # 提取“讲述并记录”之后的内容\n",
    "        info_type = \"讲述并记录\"\n",
    "        # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "        info_text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", info_text)\n",
    "        # 剔除讲述并记录信息\n",
    "        story_content = story_content[:narrator_recorder_match.start()].strip()\n",
    "    else:\n",
    "        info_text = \"NaN\"\n",
    "        info_type = \"NaN\"\n",
    "\n",
    "    # 保存故事内容到单独的txt文件\n",
    "    story_file_path = os.path.join(output_dir, f\"{story_name}.txt\")\n",
    "    with open(story_file_path, \"w\", encoding=\"utf-8\") as story_file:\n",
    "        story_file.write(story_content)\n",
    "\n",
    "    # 将故事信息添加到列表中\n",
    "    stories_data.append({\n",
    "        \"故事编号\": story_number_str,\n",
    "        \"故事标题\": story_title,\n",
    "        \"地点信息\": location,\n",
    "        \"采录者信息\": info_text if info_type != \"NaN\" else \"NaN\"\n",
    "    })\n",
    "\n",
    "# 将故事信息保存到CSV文件\n",
    "with open(csv_file_path, \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"故事编号\", \"故事标题\", \"地点信息\", \"采录者信息\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(stories_data)\n",
    "\n",
    "print(f\"\\n处理完成！结果已保存到 {output_dir} 目录中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "内蒙古的有点特殊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理故事: 100%|██████████| 641/641 [00:00<00:00, 1791.60个/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理完成！结果已保存到 /Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古 目录中。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "from tqdm import tqdm  # 导入 tqdm 库\n",
    "\n",
    "# 定义文件路径\n",
    "input_file_path = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/中国民间故事集成 山东_青海_内蒙古_黑龙江/中国民间故事集成内蒙古卷.txt\"\n",
    "output_dir = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古\"\n",
    "csv_file_path = os.path.join(output_dir, \"stories_info.csv\")\n",
    "\n",
    "number = 641\n",
    "# 创建输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 读取文件内容\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# 正则表达式匹配标题行（编号 + 可能存在的空格 + 分隔符 + 标题）\n",
    "title_pattern = re.compile(r\"(\\d{3})\\s*[•.。](.*?)\\n\")\n",
    "# 正则表达式匹配地点信息\n",
    "location_pattern = re.compile(r\"（(.*?)）\")\n",
    "# 正则表达式匹配讲述者信息\n",
    "narrator_pattern = re.compile(r\"讲\\s*述\\s*者[^\\w\\s]*(.*?)(?=\\d{4}|$)\", re.DOTALL)\n",
    "# 正则表达式匹配采录者信息\n",
    "recorder_pattern = re.compile(r\"采\\s*录\\s*者[^\\w\\s]*(.*?)(?=\\d{4}|$)\", re.DOTALL)\n",
    "# 正则表达式匹配讲述并记录信息\n",
    "narrator_recorder_pattern = re.compile(r\"讲\\s*述\\s*并\\s*记\\s*录[^\\w\\s]*(.*?)(?=\\d{4}|$)\", re.DOTALL)\n",
    "# 正则表达式匹配翻译者信息\n",
    "translator_pattern = re.compile(r\"翻\\s*译\\s*者[^\\w\\s]*(.*?)(?=\\d{4}|$)\", re.DOTALL)\n",
    "\n",
    "# 找到所有标题行的位置\n",
    "title_matches = list(title_pattern.finditer(content))\n",
    "# 初始化存储结果的列表\n",
    "stories_data = []\n",
    "\n",
    "# 遍历 001 到 725，逐个定位标题行\n",
    "for story_number in tqdm(range(1, number + 1), desc=\"处理故事\", unit=\"个\"):\n",
    "    # 格式化编号为 3 位数（如 001, 002, ..., 725）\n",
    "    story_number_str = f\"{story_number:03d}\"\n",
    "    \n",
    "    # 构造正则表达式，匹配当前编号的标题行\n",
    "    current_title_pattern = re.compile(rf\"{story_number_str}\\s*[•.。](.*?)\\n\")\n",
    "    title_match = current_title_pattern.search(content)\n",
    "    \n",
    "    if not title_match:\n",
    "        # 如果没有找到当前编号的标题行，跳过\n",
    "        continue\n",
    "\n",
    "    # 提取标题\n",
    "    story_title = title_match.group(1).strip()\n",
    "    story_name = f\"{story_number_str}{story_title}\"\n",
    "\n",
    "    # 提取地点信息\n",
    "    location_match = location_pattern.search(content[title_match.end():])\n",
    "    location = location_match.group(1).strip() if location_match else \"NaN\"\n",
    "\n",
    "    # 提取故事内容\n",
    "    if story_number < number:\n",
    "        # 查找下一个标题行\n",
    "        next_title_pattern = re.compile(rf\"{story_number + 1:03d}\\s*[•.。](.*?)\\n\")\n",
    "        next_title_match = next_title_pattern.search(content[title_match.end():])\n",
    "        if next_title_match:\n",
    "            # 当前故事的内容是从当前标题开始到下一个标题之前\n",
    "            story_content = content[title_match.start():title_match.end() + next_title_match.start()].strip()\n",
    "        else:\n",
    "            # 如果没有找到下一个标题行，则跳过\n",
    "            continue\n",
    "    else:\n",
    "        # 最后一个故事的内容是从当前标题开始到文件末尾\n",
    "        story_content = content[title_match.start():].strip()\n",
    "\n",
    "    # 提取信息（优先级：讲述者 > 采录者 > 讲述并记录 > 翻译者）\n",
    "    narrator_match = narrator_pattern.search(story_content)\n",
    "    recorder_match = recorder_pattern.search(story_content)\n",
    "    narrator_recorder_match = narrator_recorder_pattern.search(story_content)\n",
    "    translator_match = translator_pattern.search(story_content)\n",
    "\n",
    "    if narrator_match:\n",
    "        info_text = narrator_match.group(1).strip()  # 提取“讲述者”之后的内容\n",
    "        info_type = \"讲述者\"\n",
    "        # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "        info_text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", info_text)\n",
    "        # 剔除讲述者信息\n",
    "        story_content = story_content[:narrator_match.start()].strip()\n",
    "    elif recorder_match:\n",
    "        info_text = recorder_match.group(1).strip()  # 提取“采录者”之后的内容\n",
    "        info_type = \"采录者\"\n",
    "        # 进一步提取“采录者”所在行对应的内容\n",
    "        recorder_line_match = re.search(r\"采\\s*录\\s*者[^\\w\\s]*(.*)\", info_text)\n",
    "        if recorder_line_match:\n",
    "            info_text = recorder_line_match.group(1).strip()\n",
    "            # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "            info_text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", info_text)\n",
    "        else:\n",
    "            info_text = \"NaN\"\n",
    "        # 剔除采录者信息\n",
    "        story_content = story_content[:recorder_match.start()].strip()\n",
    "    elif narrator_recorder_match:\n",
    "        info_text = narrator_recorder_match.group(1).strip()  # 提取“讲述并记录”之后的内容\n",
    "        info_type = \"讲述并记录\"\n",
    "        # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "        info_text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", info_text)\n",
    "        # 剔除讲述并记录信息\n",
    "        story_content = story_content[:narrator_recorder_match.start()].strip()\n",
    "    elif translator_match:\n",
    "        info_text = translator_match.group(1).strip()  # 提取“翻译者”之后的内容\n",
    "        info_type = \"翻译者\"\n",
    "        # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "        info_text = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", info_text)\n",
    "        # 剔除翻译者信息\n",
    "        story_content = story_content[:translator_match.start()].strip()\n",
    "    else:\n",
    "        info_text = \"NaN\"\n",
    "        info_type = \"NaN\"\n",
    "\n",
    "    # 保存故事内容到单独的txt文件\n",
    "    story_file_path = os.path.join(output_dir, f\"{story_name}.txt\")\n",
    "    with open(story_file_path, \"w\", encoding=\"utf-8\") as story_file:\n",
    "        story_file.write(story_content)\n",
    "\n",
    "    # 将故事信息添加到列表中\n",
    "    stories_data.append({\n",
    "        \"故事编号\": story_number_str,\n",
    "        \"故事标题\": story_title,\n",
    "        \"地点信息\": location,\n",
    "        \"采录者信息\": info_text if info_type != \"NaN\" else \"NaN\"\n",
    "    })\n",
    "\n",
    "# 将故事信息保存到CSV文件\n",
    "with open(csv_file_path, \"w\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "    fieldnames = [\"故事编号\", \"故事标题\", \"地点信息\", \"采录者信息\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(stories_data)\n",
    "\n",
    "print(f\"\\n处理完成！结果已保存到 {output_dir} 目录中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "“采录者信息”列清洗完成！结果已保存到 /Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古/stories_info.csv 文件中。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# 定义文件路径\n",
    "input_file_path = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/中国民间故事集成 山东_青海_内蒙古_黑龙江/中国民间故事集成内蒙古卷.txt\"\n",
    "output_dir = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古\"\n",
    "csv_file_path = os.path.join(output_dir, \"stories_info.csv\")\n",
    "\n",
    "number = 641\n",
    "# 创建输出目录\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 读取文件内容\n",
    "with open(input_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()\n",
    "\n",
    "# 正则表达式匹配标题行（编号 + 可能存在的空格 + 分隔符 + 标题）\n",
    "title_pattern = re.compile(r\"(\\d{3})\\s*[•.。](.*?)\\n\")\n",
    "# 正则表达式匹配采录者信息\n",
    "recorder_pattern = re.compile(r\"采\\s*录\\s*者[^\\w\\s]*(.*)\")\n",
    "\n",
    "# 找到所有标题行的位置\n",
    "title_matches = list(title_pattern.finditer(content))\n",
    "\n",
    "# 读取现有的 stories_info.csv 文件\n",
    "with open(csv_file_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    rows = list(reader)\n",
    "\n",
    "# 遍历每个故事，重新清洗“采录者信息”列\n",
    "for row in rows:\n",
    "    story_number_str = row[\"故事编号\"]\n",
    "    \n",
    "    # 构造正则表达式，匹配当前编号的标题行\n",
    "    current_title_pattern = re.compile(rf\"{story_number_str}\\s*[•.。](.*?)\\n\")\n",
    "    title_match = current_title_pattern.search(content)\n",
    "    \n",
    "    if not title_match:\n",
    "        # 如果没有找到当前编号的标题行，跳过\n",
    "        row[\"采录者信息\"] = \"NaN\"\n",
    "        continue\n",
    "\n",
    "    # 提取故事内容\n",
    "    if int(story_number_str) < number:\n",
    "        # 查找下一个标题行\n",
    "        next_title_pattern = re.compile(rf\"{int(story_number_str) + 1:03d}\\s*[•.。](.*?)\\n\")\n",
    "        next_title_match = next_title_pattern.search(content[title_match.end():])\n",
    "        if next_title_match:\n",
    "            # 当前故事的内容是从当前标题开始到下一个标题之前\n",
    "            story_content = content[title_match.start():title_match.end() + next_title_match.start()].strip()\n",
    "        else:\n",
    "            # 如果没有找到下一个标题行，则跳过\n",
    "            row[\"采录者信息\"] = \"NaN\"\n",
    "            continue\n",
    "    else:\n",
    "        # 最后一个故事的内容是从当前标题开始到文件末尾\n",
    "        story_content = content[title_match.start():].strip()\n",
    "\n",
    "    # 查找“采录者”所在行\n",
    "    recorder_match = recorder_pattern.search(story_content)\n",
    "    if recorder_match:\n",
    "        # 提取“采录者”所在行后面的内容\n",
    "        recorder_info = recorder_match.group(1).strip()\n",
    "        # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "        recorder_info = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", recorder_info)\n",
    "        row[\"采录者信息\"] = recorder_info\n",
    "    else:\n",
    "        row[\"采录者信息\"] = \"NaN\"\n",
    "\n",
    "# 将更新后的数据写回 stories_info.csv 文件\n",
    "with open(csv_file_path, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\"故事编号\", \"故事标题\", \"地点信息\", \"采录者信息\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"\\n“采录者信息”列清洗完成！结果已保存到 {csv_file_path} 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常版的清洗采录者信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "采录者信息处理完成！结果已保存到 /Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古/stories_info.csv 文件中。\n"
     ]
    }
   ],
   "source": [
    "# 读取 stories_info.csv 文件\n",
    "with open(csv_file_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    rows = list(reader)\n",
    "\n",
    "# 处理每一行的采录者信息\n",
    "for row in rows:\n",
    "    recorder_info = row[\"采录者信息\"]\n",
    "    if recorder_info != \"NaN\":\n",
    "        # 如果采录者信息不为空，进一步提取“采录者”或“讲述并记录”之后的内容\n",
    "        recorder_match = re.search(r\"(?:采\\s*录\\s*者|讲\\s*述\\s*并\\s*记\\s*录)[^\\w\\s]*(.*)\", recorder_info)\n",
    "        if recorder_match:\n",
    "            # 提取“采录者”或“讲述并记录”之后的内容\n",
    "            recorder_info = recorder_match.group(1).strip()\n",
    "            # 去除多余的标点符号和特殊字符，只保留汉字和数字\n",
    "            recorder_info = re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", recorder_info)\n",
    "            row[\"采录者信息\"] = recorder_info\n",
    "\n",
    "# 将处理后的数据写回 stories_info.csv 文件\n",
    "with open(csv_file_path, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    fieldnames = [\"故事编号\", \"故事标题\", \"地点信息\", \"采录者信息\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"\\n采录者信息处理完成！结果已保存到 {csv_file_path} 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "清洗故事文本内容（去除脚注、段内换行等），这个代码要运行两次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据清洗完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# 定义输出目录\n",
    "output_dir = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古\"\n",
    "\n",
    "# 正则表达式匹配带圆圈编号的行（包括中英文圆圈编号）\n",
    "circle_pattern = re.compile(r\"^\\s*[①-⑳ⓐ-ⓩa-z]\\.?\\s*.*\")\n",
    "\n",
    "# 遍历所有故事的txt文件\n",
    "for file_name in os.listdir(output_dir):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        file_path = os.path.join(output_dir, file_name)\n",
    "        \n",
    "        # 读取文件内容\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # 清洗数据\n",
    "        cleaned_lines = []\n",
    "\n",
    "        for line in lines:\n",
    "            # 1. 删除带圆圈编号的行（包括中英文圆圈编号）\n",
    "            if circle_pattern.match(line):\n",
    "                continue  # 跳过带圆圈编号的行\n",
    "\n",
    "            # 2. 删除单独成一行的数字（OCR 页码）及其前后的空行\n",
    "            if re.match(r\"^\\s*\\d+\\s*$\", line):\n",
    "                continue  # 跳过单独成一行的数字\n",
    "            if len(cleaned_lines) > 0 and re.match(r\"^\\s*\\d+\\s*$\", cleaned_lines[-1]) and line.strip() == \"\":\n",
    "                continue  # 跳过单独成一行数字后的空行\n",
    "            if len(cleaned_lines) > 0 and re.match(r\"^\\s*\\d+\\s*$\", line) and cleaned_lines[-1].strip() == \"\":\n",
    "                cleaned_lines.pop()  # 删除单独成一行数字前的空行\n",
    "\n",
    "            # 将当前行加入清洗后的列表\n",
    "            cleaned_lines.append(line)\n",
    "\n",
    "        # 进一步处理段落内的换行符\n",
    "        final_lines = []\n",
    "        i = 0\n",
    "        while i < len(cleaned_lines):\n",
    "            current_line = cleaned_lines[i]\n",
    "            if i < len(cleaned_lines) - 1:\n",
    "                next_line = cleaned_lines[i + 1]\n",
    "                # 如果前一行以空格开头，后一行以文字开头，说明属于同一段落\n",
    "                if current_line.startswith(\" \") and not next_line.startswith(\" \"):\n",
    "                    final_lines.append(current_line.rstrip() + next_line)\n",
    "                    i += 2  # 跳过下一行，因为已经合并\n",
    "                    continue\n",
    "                # 如果两行都以文字开头，说明属于同一段落\n",
    "                elif not current_line.startswith(\" \") and not next_line.startswith(\" \"):\n",
    "                    final_lines.append(current_line.rstrip() + next_line)\n",
    "                    i += 2  # 跳过下一行，因为已经合并\n",
    "                    continue\n",
    "                # 如果前一行以文字开头，后一行以空格开头，则不做操作\n",
    "                else:\n",
    "                    final_lines.append(current_line)\n",
    "                    i += 1\n",
    "            else:\n",
    "                final_lines.append(current_line)\n",
    "                i += 1\n",
    "\n",
    "        # 保存清洗后的内容\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.writelines(final_lines)\n",
    "\n",
    "print(\"数据清洗完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照全部总体的故事数量重新编号，并清洗stories_info.csv这个表（去除特殊字符）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件重命名完成！\n",
      "CSV文件修改完成！\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "\n",
    "# 定义目录和文件路径\n",
    "output_dir = \"/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古\"\n",
    "csv_path = os.path.join(output_dir, \"stories_info.csv\")\n",
    "\n",
    "# 初始化编号\n",
    "start_number = 19172\n",
    "\n",
    "# 1. 按顺序遍历txt文件，重命名文件\n",
    "txt_files = [f for f in os.listdir(output_dir) if f.endswith(\".txt\")]\n",
    "txt_files.sort()  # 按文件名排序\n",
    "\n",
    "for idx, file_name in enumerate(txt_files):\n",
    "    # 构造新文件名\n",
    "    new_file_name = f\"{start_number + idx}__{file_name}\"\n",
    "    old_file_path = os.path.join(output_dir, file_name)\n",
    "    new_file_path = os.path.join(output_dir, new_file_name)\n",
    "    \n",
    "    # 重命名文件\n",
    "    os.rename(old_file_path, new_file_path)\n",
    "\n",
    "print(\"文件重命名完成！\")\n",
    "\n",
    "# 2. 读取stories_info.csv，修改故事标题列\n",
    "def clean_text(text):\n",
    "    \"\"\"删除标点符号和特殊字符，只保留汉字和数字\"\"\"\n",
    "    return re.sub(r\"[^\\u4e00-\\u9fa5\\d]\", \"\", text)\n",
    "\n",
    "# 读取CSV文件\n",
    "rows = []\n",
    "with open(csv_path, \"r\", encoding=\"utf-8\") as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    fieldnames = reader.fieldnames  # 获取表头\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "\n",
    "# 修改故事标题列\n",
    "for idx, row in enumerate(rows):\n",
    "    # 构造新的故事标题\n",
    "    story_number = row[\"故事编号\"].zfill(3)  # 补全为3位数字\n",
    "    new_title = f\"{start_number + idx}__{story_number}{row['故事标题']}\"\n",
    "    row[\"故事标题\"] = new_title\n",
    "\n",
    "    # 清洗地点信息和采录者信息列\n",
    "    row[\"地点信息\"] = clean_text(row[\"地点信息\"])\n",
    "    row[\"采录者信息\"] = clean_text(row[\"采录者信息\"])\n",
    "\n",
    "# 写回CSV文件\n",
    "with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"CSV文件修改完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改info表的内容，使得和之前“地图匹配”表一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义地区变量\n",
    "region = \"黑龙江\"\n",
    "\n",
    "# 读取CSV文件\n",
    "file_path = f'/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/{region}/stories_info.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 在地点信息一列每个单元格取值前加入地区变量\n",
    "df['地点信息'] = region + df['地点信息'].astype(str)\n",
    "\n",
    "# 新生成一列“new_name”取值为“故事标题”里的中文\n",
    "df['new_name'] = df['故事标题'].str.extract('([\\u4e00-\\u9fff]+)')  # 提取中文\n",
    "\n",
    "# 新生成一列area_group为地区变量\n",
    "df['area_group'] = region\n",
    "\n",
    "# 保存修改后的数据到新的CSV文件（可选）\n",
    "output_file_path = f'/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/{region}/stories_info_modified.csv'\n",
    "df.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面就开始合并数据到地图匹配总表中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w5/_ylk19595zl7_649y60st5680000gn/T/ipykernel_50799/2683165112.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([df_excel, df_csv_common], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的数据已保存到: /Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120地图匹配_v6.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 定义文件路径\n",
    "csv_file_path = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120OCR/内蒙古641/250120stories_info_neimenggu.csv'\n",
    "excel_file_path = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120地图匹配_v6.xlsx'\n",
    "output_excel_path = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/250120地图匹配_v6.xlsx'\n",
    "\n",
    "# 读取CSV文件\n",
    "df_csv = pd.read_csv(csv_file_path)\n",
    "\n",
    "# 读取Excel文件\n",
    "df_excel = pd.read_excel(excel_file_path)\n",
    "\n",
    "# 找到两个表中相同的列名\n",
    "common_columns = set(df_csv.columns) & set(df_excel.columns)\n",
    "\n",
    "# 如果存在相同列名\n",
    "if common_columns:\n",
    "    # 提取CSV表中与Excel表相同列名的数据\n",
    "    df_csv_common = df_csv[list(common_columns)]\n",
    "\n",
    "    # 在CSV表的数据中添加Excel表中独有的列，并填充空值\n",
    "    for column in df_excel.columns:\n",
    "        if column not in common_columns:\n",
    "            df_csv_common[column] = None  # 添加Excel独有的列，并填充空值\n",
    "\n",
    "    # 将CSV表中的数据追加到Excel表的下方\n",
    "    merged_df = pd.concat([df_excel, df_csv_common], ignore_index=True)\n",
    "\n",
    "    # 保存合并后的数据到新的Excel文件\n",
    "    merged_df.to_excel(output_excel_path, index=False)\n",
    "    print(f\"合并后的数据已保存到: {output_excel_path}\")\n",
    "else:\n",
    "    print(\"两个表没有相同的列名，无法合并。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
