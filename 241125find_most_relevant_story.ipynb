{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511bcb5e-c6ae-4d78-ab41-f808e1db7837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# 设置 API 密钥和组织\n",
    "api_key = \"sk-WO49kazJ9a1PDGbE2lPRhJ9vDG8hak5_mbD60YhIB8T3BlbkFJHbhSLNYAPwzhLHjS72qabHWqGwtBmAvgRpRwN_iYMA\"\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# 设置组织信息\n",
    "client.organization = \"org-34qJHjOz4UGZYVqv2zlohVMe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03abb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "比较文件: 100%|██████████| 4950/4950 [06:54<00:00, 11.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽样文件的评分结果已保存到 sample_scores.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# 定义文件路径\n",
    "root_folder = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/raw_data_tales'\n",
    "all_files = []\n",
    "\n",
    "# 遍历目录，收集所有文件路径\n",
    "for dirpath, _, filenames in os.walk(root_folder):\n",
    "    for filename in filenames:\n",
    "        relative_path = os.path.join(*dirpath.split(os.sep)[-2:], filename)\n",
    "        all_files.append((os.path.join(dirpath, filename), relative_path))\n",
    "\n",
    "# 随机选取100个文件\n",
    "sample_size = min(len(all_files), 100)\n",
    "selected_files = [all_files[i] for i in np.random.choice(len(all_files), sample_size, replace=False)]\n",
    "\n",
    "# 读取文件内容并存储\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "file_contents = {relative_path: read_file(file_path) for file_path, relative_path in selected_files}\n",
    "\n",
    "# 初始化文件评分字典\n",
    "scores = defaultdict(int)\n",
    "file_pairs = [(selected_files[i][1], selected_files[j][1]) for i in range(len(selected_files)) for j in range(i + 1, len(selected_files))]\n",
    "\n",
    "# 文件内容比较函数\n",
    "def compare_files(file_pair):\n",
    "    file1, file2 = file_pair\n",
    "    file1_content = file_contents[file1]\n",
    "    file2_content = file_contents[file2]\n",
    "    prompt = f\"你是一位精通中国民间故事研究的研究员，需要研究\\\"结拜\\\"主题的故事--具体而言，这个故事应包含通过特殊仪式结为兄弟姐妹的‘结拜’情节，体现超越血缘的亲密关系，基于共同信念与目标，人与人之间通过誓言与约定建立起深厚的情谊和相互扶持的纽带，反映对义气、兄弟情深与忠诚的高度推崇。根据以下两篇中国民间故事文本，请判断哪一段与\\\"结拜\\\"主题的相关程度更高。\\n\\n文本1：\\n{file1_content}\\n\\n文本2：\\n{file2_content}\\n\\n注意，请直接回答“文本1”或“文本2”，不要输出其他文字。此外，请仅依据对主题的具体解释作出判断，不使用任何外部信息、不允许推断、不允许牵强附会或过度解读。\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=3,\n",
    "            temperature=0.1,\n",
    "            top_p=0.9\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        return file_pair, answer\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_pair}: {e}\")\n",
    "        return file_pair, \"Error\"\n",
    "\n",
    "# 多线程处理文件对\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    results = list(tqdm(executor.map(compare_files, file_pairs), total=len(file_pairs), desc=\"比较文件\"))\n",
    "\n",
    "# 更新评分\n",
    "for (file1, file2), result in results:\n",
    "    if result == \"文本1\":\n",
    "        scores[file1] += 1\n",
    "    elif result == \"文本2\":\n",
    "        scores[file2] += 1\n",
    "\n",
    "# 保存结果到 CSV\n",
    "sample_results = [{\"文件路径\": file, \"内容\": file_contents[file], \"评分\": scores[file]} for file in file_contents]\n",
    "sample_df = pd.DataFrame(sample_results)\n",
    "sample_df.to_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241125gpt_sample_scores_jiebai.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"抽样文件的评分结果已保存到 sample_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4498271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Anaconda/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-11-25 03:33:30.448222: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 加载 BERT 模型\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('DMetaSoul/sbert-chinese-general-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27e1d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 17324/17324 [10:02<00:00, 28.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相似度计算完成，结果已保存为 CSV 文件。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# 获取得分最高的文件内容和路径\n",
    "sample_df = pd.read_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241125gpt_sample_scores_jiebai.csv')\n",
    "highest_score_row = sample_df.loc[sample_df['评分'].idxmax()]\n",
    "highest_score_content = highest_score_row['内容']\n",
    "\n",
    "# 文件相似度比较函数\n",
    "def compute_similarity(file_path, file_content, highest_score_content):\n",
    "    embeddings = model.encode([file_content, highest_score_content])\n",
    "    A, B = embeddings[0], embeddings[1]\n",
    "    similarity = np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "    return {'文件名': file_path, '相似度': similarity}\n",
    "\n",
    "# 遍历子文件夹中的所有.txt文件，获取文件路径列表\n",
    "folder_path = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/raw_data_tales'\n",
    "file_paths = []\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "\n",
    "# 并行处理文件\n",
    "results = []\n",
    "with ThreadPoolExecutor(max_workers=60) as executor:  # 调整 max_workers 根据系统性能\n",
    "    future_to_file = {\n",
    "        executor.submit(\n",
    "            compute_similarity,\n",
    "            file_path,\n",
    "            open(file_path, 'r', encoding='utf-8').read(),\n",
    "            highest_score_content\n",
    "        ): file_path\n",
    "        for file_path in file_paths\n",
    "    }\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_file), total=len(future_to_file), desc=\"Processing files\"):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {future_to_file[future]}: {e}\")\n",
    "\n",
    "# 将结果保存到 CSV 文件中\n",
    "output_csv_file = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241125similarity_results_jiebai_real_story.csv'\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_csv_file, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"相似度计算完成，结果已保存为 CSV 文件。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "385f6b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01170__414-女人的围腰布.txt'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.iloc[0]['文件名']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c10cf5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['文件名'] = results_df['文件名'].apply(lambda x: os.path.basename(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c95ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
