{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3716556-7855-4519-bd1d-3f6cc0faef7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique value combinations saved to /Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241105area_value_combinations.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# 文件夹路径和排除文件路径\n",
    "folder_path = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/国标码'\n",
    "exclude_file = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/国标码/china10_cnty_fromexcel_cnty_pref.csv'\n",
    "\n",
    "# 获取所有 .xls 文件的路径，排除指定文件\n",
    "all_files = glob(os.path.join(folder_path, '**/*.xls'), recursive=True)\n",
    "files_to_process = [file for file in all_files if file != exclude_file]\n",
    "\n",
    "# 定义感兴趣的字段\n",
    "columns_of_interest = ['PROVGB', 'CITYGB', 'CNTYGB', 'CPROV', 'EPROV', 'CCNTY', 'ECNTY']\n",
    "\n",
    "# 用于存储所有可能取值组合的集合\n",
    "all_combinations = set()\n",
    "\n",
    "# 遍历每个文件并提取感兴趣字段的值组合\n",
    "for file in files_to_process:\n",
    "    try:\n",
    "        # 读取Excel文件\n",
    "        df = pd.read_excel(file, usecols=columns_of_interest)\n",
    "        \n",
    "        # 去除缺失值的行，然后将感兴趣的字段转为元组形式\n",
    "        df = df.dropna(subset=columns_of_interest)\n",
    "        \n",
    "        # 添加每一行的值组合到集合中去重\n",
    "        for row in df[columns_of_interest].itertuples(index=False, name=None):\n",
    "            all_combinations.add(row)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# 将结果转换为DataFrame，并按第一列降序排列\n",
    "all_combinations_df = pd.DataFrame(list(all_combinations), columns=columns_of_interest)\n",
    "all_combinations_df = all_combinations_df.sort_values(by=columns_of_interest[0], ascending=False)\n",
    "\n",
    "# 保存到CSV文件，不带索引\n",
    "output_path = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241105area_value_combinations.csv'\n",
    "all_combinations_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"All unique value combinations saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a17568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e71037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb190fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "匹配地名:   0%|          | 0/17263 [07:32<?, ?it/s]\n",
      "匹配地名:   0%|          | 0/17263 [06:41<?, ?it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "清洗地名: 100%|██████████| 3348/3348 [00:01<00:00, 2126.93it/s]\n",
      "匹配地名: 100%|██████████| 3348/3348 [00:46<00:00, 71.24it/s]\n"
     ]
    }
   ],
   "source": [
    "clean的时候加一步操作：新增一列“nozu_area”，删除掉省份以后，“族“字及其之前的字符，列“area”如果出现“族”这个字，\n",
    "最终存要存clean之前的area内容\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm  # 用于显示进度条\n",
    "import re  # 用于正则表达式\n",
    "from joblib import Parallel, delayed  # 用于并行处理\n",
    "\n",
    "# 定义一个函数去除特殊字符和空格\n",
    "def clean_area_name(area_name):\n",
    "    area_name = re.sub(r'[^\\w\\s]', '', area_name)  # 去除特殊字符\n",
    "    area_name = re.sub(r'\\s+', '', area_name)  # 去除所有空格\n",
    "    return area_name.strip()  # 去除首尾空格\n",
    "\n",
    "# 匹配函数，增加对 name 的记录\n",
    "def match_area(area, name):\n",
    "    match = process.extractOne(area, reference_df['combined'])\n",
    "    return name, area, match[0], match[1]  # 返回 name，原始地名，匹配结果和相似度\n",
    "\n",
    "# 读取地名文件\n",
    "area_df = pd.read_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/raw_data_tales/地图匹配_0426_v4.csv')  # 包含不规范的地名\n",
    "reference_df = pd.read_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241105area_value_combinations.csv')  # 包含所有可能的地名\n",
    "\n",
    "columns_to_check = [\n",
    "    \"PROVGB_1953\", \"CITYGB_1953\", \"CNTYGB_1953\",\n",
    "    \"PROVGB_1964\", \"CITYGB_1964\", \"CNTYGB_1964\",\n",
    "    \"PROVGB_1982\", \"CITYGB_1982\", \"CNTYGB_1982\",\n",
    "    \"PROVGB_1990a\", \"CITYGB_1990a\", \"CNTYGB_1990a\",\n",
    "    \"PROVGB_2000\", \"CITYGB_2000\", \"CNTYGB_2000\",\n",
    "    \"PROVGB_2010\", \"CITYGB_2010\", \"CNTYGB_2010\"\n",
    "]\n",
    "\n",
    "# 保留所有这些列都为空的行\n",
    "area_df = area_df[area_df[columns_to_check].isnull().all(axis=1)]\n",
    "\n",
    "\n",
    "# 清洗地名\n",
    "tqdm.pandas(desc=\"清洗地名\")\n",
    "area_df['cleaned_area'] = Parallel(n_jobs=-1)(\n",
    "    delayed(clean_area_name)(area) for area in tqdm(area_df['area'], desc=\"清洗地名\")\n",
    ")\n",
    "\n",
    "reference_df['combined'] = Parallel(n_jobs=-1)(\n",
    "    delayed(clean_area_name)(f\"{row['CPROV']}{row['CCNTY']}\") for _, row in reference_df.iterrows()\n",
    ")\n",
    "\n",
    "# 匹配地名并记录结果\n",
    "tqdm.pandas(desc=\"匹配地名\")\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(match_area)(row['cleaned_area'], row['name']) for _, row in tqdm(area_df.iterrows(), total=area_df.shape[0], desc=\"匹配地名\")\n",
    ")\n",
    "\n",
    "# 将结果转换为 DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['name', 'original_area', 'matched_area', 'similarity'])\n",
    "\n",
    "# 保存结果到 CSV 文件\n",
    "results_df.to_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/matched_areas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76886220",
   "metadata": {},
   "source": [
    "读取这个表：/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241105matched_areas.csv\n",
    "如果, 'matched_area'的后2/3/4个字符出现在'original_area'中，similarity”一列低于60分，改为61分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe4eb5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name                              cleaned_original_area  \\\n",
      "1734   02561__554巧计定是非  吉林人做有自己的木匠铁匠也有自己的看病先生自己寻找草药自己配药有个畲族村寨有一户世代名医真是...   \n",
      "2565  00349__352黄花鱼和鳖鱼  上海早很早以前黄花鱼就是海里的游泳能手黄花鱼啥都好就是有点骄傲它自称是海里游泳第一其实呢比它...   \n",
      "1095     00280__283黄浦江  上海久很久以前上海还是一片荒凉的沼泽地沼泽地当中弯弯曲曲有一条河流河床很浅雨水多了泛滥成灾雨...   \n",
      "2341     02404__391飞去。  吉林这样素贞化成了一只体态娇小羽毛灰白黑相间的鸟儿像披着一身朴素的孝衣这鸟儿越过高山越过河流...   \n",
      "2141    06824__113 病了。  广东世藩听到消息后便到谭家探访谭大初对他说希望他协助捞回玉镯并提出自己出钱用水车车干塘水的办...   \n",
      "\n",
      "     matched_area  similarity  \n",
      "1734        吉林洮南市          24  \n",
      "2565        广东花都区          24  \n",
      "1095        青海久治县          24  \n",
      "2341        云南宜良县          24  \n",
      "2141         广东梅县          30  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "file_path = '/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/matched_areas.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 定义一个函数检查条件并修改 similarity\n",
    "def update_similarity(row):\n",
    "    matched_area = row['matched_area']\n",
    "    original_area = row['cleaned_original_area']\n",
    "    similarity = row['similarity']\n",
    "    \n",
    "    # 检查后2、3、4个字符是否出现在 original_area 中\n",
    "    for i in range(2, 5):  # 从 2 到 4\n",
    "        if matched_area[-i:] in original_area and similarity < 60:\n",
    "            return 61  # 修改为 61 分\n",
    "    return similarity  # 不修改，返回原值\n",
    "\n",
    "# 应用函数并更新 similarity 列\n",
    "df['similarity'] = df.apply(update_similarity, axis=1)\n",
    "\n",
    "# 按照 similarity 列升序排序\n",
    "df = df.sort_values(by='similarity', ascending=True)\n",
    "\n",
    "# 保存修改后的 DataFrame 回 CSV 文件（可选）\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "# 显示更新后的 DataFrame（可选）\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095fa89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0afa9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adaa8794",
   "metadata": {},
   "source": [
    "删除省份名称后紧接的“上”或“下”字，以及“族”字及其之间的内容和“族”字本身："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b9be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = [\n",
    "    \"北京\", \"天津\", \"河北\", \"山西\", \"内蒙古\",\n",
    "    \"辽宁\", \"吉林\", \"黑龙江\", \"上海\", \"江苏\",\n",
    "    \"浙江\", \"安徽\", \"福建\", \"江西\", \"山东\",\n",
    "    \"河南\", \"湖北\", \"湖南\", \"广东\", \"广西\",\n",
    "    \"海南\", \"重庆\", \"四川\", \"贵州\", \"云南\",\n",
    "    \"西藏\", \"陕西\", \"甘肃\", \"青海\", \"宁夏\",\n",
    "    \"新疆\", \"香港\", \"澳门\", \"台湾\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc342194",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "清洗地名: 100%|██████████| 3348/3348 [00:01<00:00, 2349.85it/s]\n",
      "匹配地名: 100%|██████████| 3348/3348 [00:50<00:00, 66.42it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "from tqdm import tqdm  # 用于显示进度条\n",
    "import re  # 用于正则表达式\n",
    "from joblib import Parallel, delayed  # 用于并行处理\n",
    "\n",
    "# 定义一个函数去除特殊字符和空格，并处理“族”字\n",
    "def clean_area_name(area_name):\n",
    "    # 去除特殊字符\n",
    "    area_name = re.sub(r'[^\\w\\s]', '', area_name)  \n",
    "    # 去除所有空格\n",
    "    area_name = re.sub(r'\\s+', '', area_name)  \n",
    "    return area_name.strip()  # 去除首尾空格\n",
    "\n",
    "\n",
    "def remove_province_and_zu(area_name, provinces):\n",
    "    # 遍历省份名称\n",
    "    for province in provinces:\n",
    "        if area_name.startswith(province):\n",
    "            # 使用正则表达式删除省份名称后紧接的“上”或“下”，以及“族”字及其之间的内容\n",
    "            area_name = re.sub(rf'^{province}(上|下)?[^族]*族', province, area_name)\n",
    "            break  # 找到匹配的省份后可以退出循环\n",
    "    return area_name.strip()  # 返回清洗后的名称\n",
    "\n",
    "\n",
    "\n",
    "# 匹配函数，增加对 name 的记录\n",
    "def match_area(area, name):\n",
    "    match = process.extractOne(area, reference_df['combined'])\n",
    "    return name, area, match[0], match[1]  # 返回 name，原始地名，匹配结果和相似度\n",
    "\n",
    "# 读取地名文件\n",
    "area_df = pd.read_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/raw_data_tales/地图匹配_0426_v4.csv')  # 包含不规范的地名\n",
    "reference_df = pd.read_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241105area_value_combinations.csv')  # 包含所有可能的地名\n",
    "\n",
    "columns_to_check = [\n",
    "    \"PROVGB_1953\", \"CITYGB_1953\", \"CNTYGB_1953\",\n",
    "    \"PROVGB_1964\", \"CITYGB_1964\", \"CNTYGB_1964\",\n",
    "    \"PROVGB_1982\", \"CITYGB_1982\", \"CNTYGB_1982\",\n",
    "    \"PROVGB_1990a\", \"CITYGB_1990a\", \"CNTYGB_1990a\",\n",
    "    \"PROVGB_2000\", \"CITYGB_2000\", \"CNTYGB_2000\",\n",
    "    \"PROVGB_2010\", \"CITYGB_2010\", \"CNTYGB_2010\"\n",
    "]\n",
    "\n",
    "# 保留所有这些列都为空的行\n",
    "area_df = area_df[area_df[columns_to_check].isnull().all(axis=1)]\n",
    "\n",
    "\n",
    "# 新增 nozu_area 列\n",
    "area_df['nozu_area'] = area_df['area'].apply(lambda x: remove_province_and_zu(x, provinces))\n",
    "\n",
    "# 清洗地名\n",
    "tqdm.pandas(desc=\"清洗地名\")\n",
    "area_df['cleaned_area'] = Parallel(n_jobs=-1)(\n",
    "    delayed(clean_area_name)(area) for area in tqdm(area_df['nozu_area'], desc=\"清洗地名\")\n",
    ")\n",
    "\n",
    "reference_df['combined'] = Parallel(n_jobs=-1)(\n",
    "    delayed(clean_area_name)(f\"{row['CPROV']}{row['CCNTY']}\") for _, row in reference_df.iterrows()\n",
    ")\n",
    "\n",
    "# 匹配地名并记录结果\n",
    "tqdm.pandas(desc=\"匹配地名\")\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(match_area)(row['cleaned_area'], row['name']) for _, row in tqdm(area_df.iterrows(), total=area_df.shape[0], desc=\"匹配地名\")\n",
    ")\n",
    "\n",
    "# 将结果转换为 DataFrame\n",
    "results_df = pd.DataFrame(results, columns=['name', 'cleaned_original_area', 'matched_area', 'similarity'])\n",
    "\n",
    "# 保存结果到 CSV 文件\n",
    "results_df.to_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/matched_areas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bb53b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "matched_areas_df = pd.read_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/matched_areas.csv')\n",
    "raw_data_tales_df = pd.read_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/data/raw_data_tales/地图匹配_0426_v4.csv')\n",
    "\n",
    "# 合并数据，依据 \"name\" 列\n",
    "merged_df = pd.merge(matched_areas_df, raw_data_tales_df[['name', 'area']], on='name', how='left')\n",
    "\n",
    "# 保存结果到新的 CSV 文件\n",
    "merged_df.to_csv('/Users/zhaorunping/Desktop/Research_Onging/2410_LSE_Xue/result/241105cleaned_matched_areas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c4290f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
